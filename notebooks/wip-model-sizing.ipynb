{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* https://platform.openai.com/docs/guides/fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.util import distributionPreservingDownsample, prettyPrintFineTuneJob, tersePrintFineTuneJob, tersePrintFineTuneJobHeader, makeJobsDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv; load_dotenv()\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sms data file with 5572 rows, kept 5169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prompt</th>\n",
       "      <th>spam_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             prompt  spam_flag\n",
       "0   ham  Go until jurong point, crazy.. Available only ...      False\n",
       "1   ham                      Ok lar... Joking wif u oni...      False\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...       True\n",
       "3   ham  U dun say so early hor... U c already then say...      False\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam_all = pd.read_csv('../data/kaggle_sms_spam.csv', encoding='latin-1')[['label', 'prompt']]\n",
    "\n",
    "# Create spam_flag column, a boolean indicating spam or not\n",
    "sms_spam_all['spam_flag'] = sms_spam_all['label'].apply(lambda x: True if x == 'spam' else False)\n",
    "\n",
    "# Some datasets may have duplicate prompts, we want to remove these\n",
    "sms_spam = sms_spam_all.drop_duplicates(subset=['prompt'])\n",
    "\n",
    "print(\"Loaded sms data file with {} rows, kept {}\".format(len(sms_spam_all), len(sms_spam)))\n",
    "sms_spam.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemPrompt = \"You are a system for categorizing SMS text messages as being unwanted spam or normal messages.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create downsampled datasets at various sizes\n",
    "\n",
    "We want to see how the dataset size affects model training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_sizes = [25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400]\n",
    "sample_sizes = [100,150,200]\n",
    "\n",
    "# map sample sizes to distributionPreservingDownsample(sms_spam, 'spam_flag', x)\n",
    "# display(sms_spam)\n",
    "downsampled_datasets = {x: distributionPreservingDownsample(sms_spam, 'spam_flag', x) for x in sample_sizes}\n",
    "# downsampled_datasets\n",
    "jsonl_files = []\n",
    "for sample_size in downsampled_datasets:\n",
    "    jsonl_data_path = f\"../data/temp/downsampled_{sample_size}.jsonl\"\n",
    "    jsonl_files.append(jsonl_data_path)\n",
    "    with open(jsonl_data_path, 'w') as f:\n",
    "        for index, row in downsampled_datasets[sample_size].iterrows():\n",
    "            f.write(json.dumps({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": systemPrompt},\n",
    "                    {\"role\": \"user\", \"content\": row['prompt']},\n",
    "                    {\"role\": \"assistant\", \"content\": \"spam\" if row['spam_flag'] else \"ham\"}\n",
    "                ]\n",
    "            }) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runFineTuning(jsonl_data_path):\n",
    "    uploadedFile = openai.File.create(\n",
    "        file=open(jsonl_data_path, \"rb\"),\n",
    "        purpose='fine-tune'\n",
    "    )\n",
    "    job = openai.FineTuningJob.create(training_file=uploadedFile.id, model=\"gpt-3.5-turbo\")\n",
    "    print(\"Submitted job {} for file {}\".format(job.id, jsonl_data_path))\n",
    "    return job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted job ftjob-tB505C0UG0oE8A0tO8DiWVsv for file ../data/temp/downsampled_100.jsonl\n",
      "Submitted job ftjob-hjCv26zXKV13we6T1GoZSU3I for file ../data/temp/downsampled_150.jsonl\n",
      "Submitted job ftjob-KUl5tSNid5Rq08EK9JFiySDt for file ../data/temp/downsampled_200.jsonl\n"
     ]
    }
   ],
   "source": [
    "submitted_jobs = []\n",
    "for jsonl_file in jsonl_files:\n",
    "    submitted_jobs.append({\n",
    "        \"jsonl_file\": jsonl_file,\n",
    "        \"job\": runFineTuning(jsonl_file)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated at 2023-11-06 07:32:44.657746\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Training File</th>\n",
       "      <th>Status</th>\n",
       "      <th>Duration</th>\n",
       "      <th>TrainedTokens</th>\n",
       "      <th>TokensPerMinute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ftjob-KUl5tSNid5Rq08EK9JFiySDt</td>\n",
       "      <td>file-tmOKf3KsbaOQLcIDMvx7lMbq</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>16.916667</td>\n",
       "      <td>31632</td>\n",
       "      <td>1869.871921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ftjob-hjCv26zXKV13we6T1GoZSU3I</td>\n",
       "      <td>file-MTHHGTfNOed6X1YWWF1zX8Ud</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>18.550000</td>\n",
       "      <td>23943</td>\n",
       "      <td>1290.727763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ftjob-tB505C0UG0oE8A0tO8DiWVsv</td>\n",
       "      <td>file-PW2XKUivTmO7VWBQ8OY7ZCPa</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>13.966667</td>\n",
       "      <td>16536</td>\n",
       "      <td>1183.961814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ftjob-GWOixlqvNI2QqJza3U8dXwdw</td>\n",
       "      <td>file-MO8Iqtp7D7mU4YkaqNfuYVmg</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>9.816667</td>\n",
       "      <td>12156</td>\n",
       "      <td>1238.302207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ftjob-bnNcTibuWGgZ8vmzpr3PEuk9</td>\n",
       "      <td>file-zbeYBgkkQDZzvMnZY4IPc76K</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>8118</td>\n",
       "      <td>1323.586957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ftjob-r3GPkAgJzHT04XrwvJlhQAEO</td>\n",
       "      <td>file-dP2rnjZABe7xg0GjddnL5yzI</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>5744</td>\n",
       "      <td>926.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ftjob-3xQGCgLB44R1C5jG0hrvcIbt</td>\n",
       "      <td>file-A9NBysw0N5tsSopAdpkcOF6S</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>49.483333</td>\n",
       "      <td>81474</td>\n",
       "      <td>1646.493769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ftjob-Y5a4mgDfDooMfuXv4nI8g28E</td>\n",
       "      <td>file-A9NBysw0N5tsSopAdpkcOF6S</td>\n",
       "      <td>cancelled</td>\n",
       "      <td>9183.544276</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ID                  Training File     Status  \\\n",
       "0  ftjob-KUl5tSNid5Rq08EK9JFiySDt  file-tmOKf3KsbaOQLcIDMvx7lMbq  succeeded   \n",
       "1  ftjob-hjCv26zXKV13we6T1GoZSU3I  file-MTHHGTfNOed6X1YWWF1zX8Ud  succeeded   \n",
       "2  ftjob-tB505C0UG0oE8A0tO8DiWVsv  file-PW2XKUivTmO7VWBQ8OY7ZCPa  succeeded   \n",
       "3  ftjob-GWOixlqvNI2QqJza3U8dXwdw  file-MO8Iqtp7D7mU4YkaqNfuYVmg  succeeded   \n",
       "4  ftjob-bnNcTibuWGgZ8vmzpr3PEuk9  file-zbeYBgkkQDZzvMnZY4IPc76K  succeeded   \n",
       "5  ftjob-r3GPkAgJzHT04XrwvJlhQAEO  file-dP2rnjZABe7xg0GjddnL5yzI  succeeded   \n",
       "6  ftjob-3xQGCgLB44R1C5jG0hrvcIbt  file-A9NBysw0N5tsSopAdpkcOF6S  succeeded   \n",
       "7  ftjob-Y5a4mgDfDooMfuXv4nI8g28E  file-A9NBysw0N5tsSopAdpkcOF6S  cancelled   \n",
       "\n",
       "      Duration  TrainedTokens  TokensPerMinute  \n",
       "0    16.916667          31632      1869.871921  \n",
       "1    18.550000          23943      1290.727763  \n",
       "2    13.966667          16536      1183.961814  \n",
       "3     9.816667          12156      1238.302207  \n",
       "4     6.133333           8118      1323.586957  \n",
       "5     6.200000           5744       926.451613  \n",
       "6    49.483333          81474      1646.493769  \n",
       "7  9183.544276              0         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/andrew/Software/hypercolor/applied-ai-fine-tuning/notebooks/wip-model-sizing.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrew/Software/hypercolor/applied-ai-fine-tuning/notebooks/wip-model-sizing.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUpdated at \u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrew/Software/hypercolor/applied-ai-fine-tuning/notebooks/wip-model-sizing.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m display(df)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andrew/Software/hypercolor/applied-ai-fine-tuning/notebooks/wip-model-sizing.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m10\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    current_jobs = openai.FineTuningJob.list(limit=10)\n",
    "    df = makeJobsDataframe(current_jobs.data)\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Updated at {datetime.now()}\")\n",
    "    display(df)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get job details - training is ready when \"fine_tuned_model\" is no longer null\n",
    "# jobId = job.id\n",
    "jobId = \"ftjob-3xQGCgLB44R1C5jG0hrvcIbt\"\n",
    "status = openai.FineTuningJob.retrieve(jobId)\n",
    "display(status)\n",
    "\n",
    "if status.fine_tuned_model is None:\n",
    "    print(\"Training not complete yet\")\n",
    "else:\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "fineTunedModelId = status.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x12fa14230> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-3xQGCgLB44R1C5jG0hrvcIbt\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698726834,\n",
       "      \"finished_at\": 1698729803,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:aa-engineering::8FbVkEom\",\n",
       "      \"organization_id\": \"org-n3iT5I0sZST0QX1nSKkPHmb7\",\n",
       "      \"result_files\": [\n",
       "        \"file-EnSXF8M6qBUkOhQVdCW3CvfZ\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-A9NBysw0N5tsSopAdpkcOF6S\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 81474,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-Y5a4mgDfDooMfuXv4nI8g28E\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1698726552,\n",
       "      \"finished_at\": null,\n",
       "      \"fine_tuned_model\": null,\n",
       "      \"organization_id\": \"org-n3iT5I0sZST0QX1nSKkPHmb7\",\n",
       "      \"result_files\": [],\n",
       "      \"status\": \"cancelled\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-A9NBysw0N5tsSopAdpkcOF6S\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": null,\n",
       "      \"error\": null\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": false\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other useful commands\n",
    "jobs = openai.FineTuningJob.list(limit=10)\n",
    "#openai.FineTuningJob.list_events(id=job.id, limit=10)\n",
    "#openai.FineTuningJob.cancel(job.id)\n",
    "\n",
    "jobs\n",
    "# prettyPrintFineTuneJob(jobs.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
