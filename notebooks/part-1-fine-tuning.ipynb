{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This notebook demonstrates fine-tuning GPT 3.5 for text classification on a dataset of SMS text messages.\n",
    "\n",
    "The following steps are covered:\n",
    "\n",
    "* Loading and enriching SMS dataset\n",
    "* Downsampling the dataset for fine tuning\n",
    "* Training three fine-tuned models with sizes: 50, 100, 200\n",
    "* Experimenting with the fine-tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "* Python 3 environment\n",
    "    * python3 -m venv venv\n",
    "    * Select venv kernel in VS Code\n",
    "        * Upper-right corner of notebook in editor\n",
    "* OpenAI Account\n",
    "    * Need a valid API key: https://platform.openai.com/account/api-keys\n",
    "* OpenAI Python Module\n",
    "    * https://github.com/openai/openai-python\n",
    "    * pip install --pre openai\n",
    "    * Configure with API Key: \n",
    "        * Create .env file with `OPENAI_API_KEY=sk_XXXX_...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# %pip install pandas\n",
    "# %pip install python-dotenv\n",
    "# %pip install openai\n",
    "# %pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* https://platform.openai.com/docs/guides/fine-tuning\n",
    "* https://platform.openai.com/docs/api-reference/fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "# from openai import AsyncOpenAI\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.util import getTrainTestSplit, makeJobsDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv; load_dotenv()\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SMS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sms data file with 5572 rows, kept 5169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prompt</th>\n",
       "      <th>spam_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             prompt  spam_flag\n",
       "0   ham  Go until jurong point, crazy.. Available only ...      False\n",
       "1   ham                      Ok lar... Joking wif u oni...      False\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...       True\n",
       "3   ham  U dun say so early hor... U c already then say...      False\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam_all = pd.read_csv('../data/kaggle_sms_spam.csv', encoding='latin-1')[['label', 'prompt']]\n",
    "sms_spam_all['spam_flag'] = sms_spam_all['label'].apply(lambda x: True if x == 'spam' else False)\n",
    "sms_spam = sms_spam_all.drop_duplicates(subset=['prompt'])\n",
    "print(\"Loaded sms data file with {} rows, kept {}\".format(len(sms_spam_all), len(sms_spam)))\n",
    "sms_spam.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemPrompt = \"You are a system for categorizing SMS text messages as being unwanted spam or normal messages.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create downsampled datasets at various sizes\n",
    "\n",
    "We want to see how the dataset size affects model training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [50, 60, 70, 80, 90, 100]\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    \n",
    "    train_data, test_data = getTrainTestSplit(sms_spam, 'spam_flag', sample_size, 200)\n",
    "\n",
    "    model_path = f\"../data/temp/model_{sample_size}\"\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    with open(f\"{model_path}/training.jsonl\", 'w') as f:\n",
    "        for index, row in train_data.iterrows():\n",
    "            f.write(json.dumps({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": systemPrompt},\n",
    "                    {\"role\": \"user\", \"content\": row['prompt']},\n",
    "                    {\"role\": \"assistant\", \"content\": \"spam\" if row['spam_flag'] else \"ham\"}\n",
    "                ]\n",
    "            }) + \"\\n\")\n",
    "\n",
    "    with open(f\"{model_path}/validation.jsonl\", 'w') as f:\n",
    "        for index, row in train_data.iterrows():\n",
    "            f.write(json.dumps({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": systemPrompt},\n",
    "                    {\"role\": \"user\", \"content\": row['prompt']},\n",
    "                    {\"role\": \"assistant\", \"content\": \"spam\" if row['spam_flag'] else \"ham\"}\n",
    "                ]\n",
    "            }) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundationModel = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "def runFineTuning(training_data_path, validation_data_path):\n",
    "    print(\"Uploading training file: {}\".format(training_data_path))\n",
    "    training_file = client.files.create(\n",
    "        file=open(training_data_path, \"rb\"),\n",
    "        purpose='fine-tune'\n",
    "    )\n",
    "    print(\"Uploading validation file: {}\".format(validation_data_path))\n",
    "    validation_file = client.files.create(\n",
    "        file=open(validation_data_path, \"rb\"),\n",
    "        purpose='fine-tune'\n",
    "    )\n",
    "    print(\"Submitting fine-tuning job for foundation model {}\".format(foundationModel))\n",
    "    job = client.fine_tuning.jobs.create(training_file=training_file.id, validation_file=validation_file.id, model=foundationModel)\n",
    "    print(\"Submitted job {}\".format(job.id))\n",
    "    return job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a training job for each sample size we are testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading training file\n",
      "Uploading validation file\n",
      "Submitting fine-tuning job\n",
      "Submitted job ftjob-LjORF6u7Ecg2yJFSWImMnz5Y for file ../data/temp/model_50/training.jsonl\n",
      "Uploading training file\n",
      "Uploading validation file\n",
      "Submitting fine-tuning job\n",
      "Submitted job ftjob-9YlZ7FlA1dGH9okqtLTwlwel for file ../data/temp/model_100/training.jsonl\n",
      "Uploading training file\n",
      "Uploading validation file\n",
      "Submitting fine-tuning job\n",
      "Submitted job ftjob-t2i8QMqXO72xxTWqWXairaQV for file ../data/temp/model_200/training.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Running this cell will start jobs with OpenAI and incur usage cost\n",
    "\n",
    "# sizes_to_run = [50, 60, 70]\n",
    "# sizes_to_run = [80, 90]\n",
    "sizes_to_run = [50, 100, 200]\n",
    "\n",
    "submitted_jobs = []\n",
    "for sample_size in sizes_to_run:\n",
    "    training_data_path = f\"../data/temp/model_{sample_size}/training.jsonl\"\n",
    "    validation_data_path = f\"../data/temp/model_{sample_size}/validation.jsonl\"\n",
    "    job = runFineTuning(training_data_path, validation_data_path)\n",
    "    with open(f\"../data/temp/model_{sample_size}/job_start.json\", 'w') as f:\n",
    "        json.dump(job.__str__(), f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated at 2023-11-09 15:04:42.252467\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Training File</th>\n",
       "      <th>Status</th>\n",
       "      <th>Duration</th>\n",
       "      <th>TrainedTokens</th>\n",
       "      <th>TokensPerMinute</th>\n",
       "      <th>FT ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ftjob-t2i8QMqXO72xxTWqWXairaQV</td>\n",
       "      <td>file-0mj0jsPJbHvjyWdvkdGkytGV</td>\n",
       "      <td>validating_files</td>\n",
       "      <td>6.520852</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ftjob-9YlZ7FlA1dGH9okqtLTwlwel</td>\n",
       "      <td>file-qN50RM8wcZ8Yu9DavWkbDEWz</td>\n",
       "      <td>running</td>\n",
       "      <td>6.554185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ftjob-LjORF6u7Ecg2yJFSWImMnz5Y</td>\n",
       "      <td>file-YG6fuUrWwzbtML29IXfl163W</td>\n",
       "      <td>running</td>\n",
       "      <td>6.620852</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ftjob-PpqU2UuljKnZsCh3yAZlSh5h</td>\n",
       "      <td>file-YhXQKR9V4gLko4we49TCwIZY</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>24.533333</td>\n",
       "      <td>14916</td>\n",
       "      <td>607.989130</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8J5R54uN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ftjob-VYgKmu5y11PK4stT5EFJ1EHE</td>\n",
       "      <td>file-d2jrGfwaE0oBTDZ1uABEaQXI</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>22.183333</td>\n",
       "      <td>13491</td>\n",
       "      <td>608.159279</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8J5OmXlv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ftjob-14hf6eczeaaST4V6Tniso8DU</td>\n",
       "      <td>file-XC0lxrDfmQg4t4gAQ1jmNVge</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>23.416667</td>\n",
       "      <td>11802</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8J56h9E9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ftjob-kJDKNUXtkOjJ6f1ZlZTIMwk3</td>\n",
       "      <td>file-jBE3mjrdneN2u94yu9c8hhCh</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>19.450000</td>\n",
       "      <td>10254</td>\n",
       "      <td>527.197943</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8J52owfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ftjob-LiL1r8rE2HEpdaj4KYnIjz9U</td>\n",
       "      <td>file-JyvEGeQTceZWqs5gtcwX314T</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>36.450000</td>\n",
       "      <td>32352</td>\n",
       "      <td>887.572016</td>\n",
       "      <td>ft:gpt-3.5-turbo-0613:hypercolor::8J4w70rh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ftjob-Y9CLf0O6axyYeHU3b3pNFrZc</td>\n",
       "      <td>file-Dgml7KFJvBrAlIDQ5LlSSbVk</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>22.050000</td>\n",
       "      <td>16455</td>\n",
       "      <td>746.258503</td>\n",
       "      <td>ft:gpt-3.5-turbo-0613:hypercolor::8J4dFhGo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ftjob-FMNe8R1qb21f4m4LywYxcdxp</td>\n",
       "      <td>file-a4ci3mqKw1CbSyNrQUxpZza7</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>17.433333</td>\n",
       "      <td>8658</td>\n",
       "      <td>496.634799</td>\n",
       "      <td>ft:gpt-3.5-turbo-0613:hypercolor::8J4N4EYY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ID                  Training File  \\\n",
       "0  ftjob-t2i8QMqXO72xxTWqWXairaQV  file-0mj0jsPJbHvjyWdvkdGkytGV   \n",
       "1  ftjob-9YlZ7FlA1dGH9okqtLTwlwel  file-qN50RM8wcZ8Yu9DavWkbDEWz   \n",
       "2  ftjob-LjORF6u7Ecg2yJFSWImMnz5Y  file-YG6fuUrWwzbtML29IXfl163W   \n",
       "3  ftjob-PpqU2UuljKnZsCh3yAZlSh5h  file-YhXQKR9V4gLko4we49TCwIZY   \n",
       "4  ftjob-VYgKmu5y11PK4stT5EFJ1EHE  file-d2jrGfwaE0oBTDZ1uABEaQXI   \n",
       "5  ftjob-14hf6eczeaaST4V6Tniso8DU  file-XC0lxrDfmQg4t4gAQ1jmNVge   \n",
       "6  ftjob-kJDKNUXtkOjJ6f1ZlZTIMwk3  file-jBE3mjrdneN2u94yu9c8hhCh   \n",
       "7  ftjob-LiL1r8rE2HEpdaj4KYnIjz9U  file-JyvEGeQTceZWqs5gtcwX314T   \n",
       "8  ftjob-Y9CLf0O6axyYeHU3b3pNFrZc  file-Dgml7KFJvBrAlIDQ5LlSSbVk   \n",
       "9  ftjob-FMNe8R1qb21f4m4LywYxcdxp  file-a4ci3mqKw1CbSyNrQUxpZza7   \n",
       "\n",
       "             Status   Duration  TrainedTokens  TokensPerMinute  \\\n",
       "0  validating_files   6.520852              0         0.000000   \n",
       "1           running   6.554185              0         0.000000   \n",
       "2           running   6.620852              0         0.000000   \n",
       "3         succeeded  24.533333          14916       607.989130   \n",
       "4         succeeded  22.183333          13491       608.159279   \n",
       "5         succeeded  23.416667          11802       504.000000   \n",
       "6         succeeded  19.450000          10254       527.197943   \n",
       "7         succeeded  36.450000          32352       887.572016   \n",
       "8         succeeded  22.050000          16455       746.258503   \n",
       "9         succeeded  17.433333           8658       496.634799   \n",
       "\n",
       "                                        FT ID  \n",
       "0                                        None  \n",
       "1                                        None  \n",
       "2                                        None  \n",
       "3  ft:gpt-3.5-turbo-1106:hypercolor::8J5R54uN  \n",
       "4  ft:gpt-3.5-turbo-1106:hypercolor::8J5OmXlv  \n",
       "5  ft:gpt-3.5-turbo-1106:hypercolor::8J56h9E9  \n",
       "6  ft:gpt-3.5-turbo-1106:hypercolor::8J52owfl  \n",
       "7  ft:gpt-3.5-turbo-0613:hypercolor::8J4w70rh  \n",
       "8  ft:gpt-3.5-turbo-0613:hypercolor::8J4dFhGo  \n",
       "9  ft:gpt-3.5-turbo-0613:hypercolor::8J4N4EYY  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while True:\n",
    "    current_jobs = client.fine_tuning.jobs.list(limit=10)\n",
    "    df = makeJobsDataframe(current_jobs.data)\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Updated at {datetime.now()}\")\n",
    "    display(df)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other useful commands\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "#client.fine_tuning.jobs.list_events(id=job.id, limit=10)\n",
    "#client.fine_tuning.jobs.cancel(job.id)\n",
    "#client.fine_tuning.jobs.retrieve(id='ftjob-KUl5tSNid5Rq08EK9JFiySDt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Size to Model ID\n",
    "completed_models = {\n",
    "    50: 'ft:gpt-3.5-turbo-0613:hypercolor::8J4N4EYY',\n",
    "    60: 'ft:gpt-3.5-turbo-1106:hypercolor::8J52owfl',\n",
    "    70: 'ft:gpt-3.5-turbo-1106:hypercolor::8J56h9E9',\n",
    "    80: 'ft:gpt-3.5-turbo-1106:hypercolor::8J5OmXlv',\n",
    "    90: 'ft:gpt-3.5-turbo-1106:hypercolor::8J5R54uN',\n",
    "    100: 'ft:gpt-3.5-turbo-0613:hypercolor::8J4dFhGo',\n",
    "    200: 'ft:gpt-3.5-turbo-0613:aa-engineering::8IAIy8LD'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpamClassification_FineTune(fineTunedModelId, prompt):\n",
    "  completion = client.chat.completions.create(\n",
    "    model=fineTunedModelId,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": systemPrompt},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  result = completion.choices[0].message.content.lower() == 'spam'\n",
    "  # print(prompt, \"=>\", result)\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSpamClassification_FineTune(completed_models[50], \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSpamClassification_FineTune(completed_models[50], \"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
