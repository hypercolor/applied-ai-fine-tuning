{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This notebook demonstrates fine-tuning GPT 3.5 for text classification on a dataset of SMS text messages.\n",
    "\n",
    "The following steps are covered:\n",
    "\n",
    "* Loading and enriching SMS dataset\n",
    "* Downsampling the dataset for fine tuning\n",
    "* Training three fine-tuned models with sizes: 50, 100, 200\n",
    "* Experimenting with the fine-tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "* Python 3 environment\n",
    "    * python3 -m venv venv\n",
    "    * Select venv kernel in VS Code\n",
    "        * Upper-right corner of notebook in editor\n",
    "* OpenAI Account\n",
    "    * Need a valid API key: https://platform.openai.com/account/api-keys\n",
    "* OpenAI Python Module\n",
    "    * https://github.com/openai/openai-python\n",
    "    * pip install --pre openai\n",
    "    * Configure with API Key: \n",
    "        * Create .env file with `OPENAI_API_KEY=sk_XXXX_...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# %pip install pandas\n",
    "# %pip install python-dotenv\n",
    "# %pip install openai\n",
    "# %pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* https://platform.openai.com/docs/guides/fine-tuning\n",
    "* https://platform.openai.com/docs/api-reference/fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "# from openai import AsyncOpenAI\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.util import getTrainTestSplit, makeJobsDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv; load_dotenv()\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SMS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sms data file with 5572 rows, kept 5169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prompt</th>\n",
       "      <th>spam_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             prompt  spam_flag\n",
       "0   ham  Go until jurong point, crazy.. Available only ...      False\n",
       "1   ham                      Ok lar... Joking wif u oni...      False\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...       True\n",
       "3   ham  U dun say so early hor... U c already then say...      False\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam_all = pd.read_csv('../data/kaggle_sms_spam.csv', encoding='latin-1')[['label', 'prompt']]\n",
    "sms_spam_all['spam_flag'] = sms_spam_all['label'].apply(lambda x: True if x == 'spam' else False)\n",
    "sms_spam = sms_spam_all.drop_duplicates(subset=['prompt'])\n",
    "print(\"Loaded sms data file with {} rows, kept {}\".format(len(sms_spam_all), len(sms_spam)))\n",
    "sms_spam.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemPrompt = \"You are a system for categorizing SMS text messages as being unwanted spam or normal messages.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create downsampled datasets at various sizes\n",
    "\n",
    "We want to see how the dataset size affects model training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [50, 60, 70, 80, 90, 100]\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    \n",
    "    train_data, test_data = getTrainTestSplit(sms_spam, 'spam_flag', sample_size, 200)\n",
    "\n",
    "    model_path = f\"../data/temp/model_{sample_size}\"\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    with open(f\"{model_path}/training.jsonl\", 'w') as f:\n",
    "        for index, row in train_data.iterrows():\n",
    "            f.write(json.dumps({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": systemPrompt},\n",
    "                    {\"role\": \"user\", \"content\": row['prompt']},\n",
    "                    {\"role\": \"assistant\", \"content\": \"spam\" if row['spam_flag'] else \"ham\"}\n",
    "                ]\n",
    "            }) + \"\\n\")\n",
    "\n",
    "    with open(f\"{model_path}/validation.jsonl\", 'w') as f:\n",
    "        for index, row in train_data.iterrows():\n",
    "            f.write(json.dumps({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": systemPrompt},\n",
    "                    {\"role\": \"user\", \"content\": row['prompt']},\n",
    "                    {\"role\": \"assistant\", \"content\": \"spam\" if row['spam_flag'] else \"ham\"}\n",
    "                ]\n",
    "            }) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundationModel = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "def runFineTuning(training_data_path, validation_data_path):\n",
    "    print(\"Uploading training file: {}\".format(training_data_path))\n",
    "    training_file = client.files.create(\n",
    "        file=open(training_data_path, \"rb\"),\n",
    "        purpose='fine-tune'\n",
    "    )\n",
    "    print(\"Uploading validation file: {}\".format(validation_data_path))\n",
    "    validation_file = client.files.create(\n",
    "        file=open(validation_data_path, \"rb\"),\n",
    "        purpose='fine-tune'\n",
    "    )\n",
    "    print(\"Submitting fine-tuning job for foundation model {}\".format(foundationModel))\n",
    "    job = client.fine_tuning.jobs.create(training_file=training_file.id, validation_file=validation_file.id, model=foundationModel)\n",
    "    print(\"Submitted job {}\".format(job.id))\n",
    "    return job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a training job for each sample size we are testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading training file\n",
      "Uploading validation file\n",
      "Submitting fine-tuning job\n",
      "Submitted job ftjob-kJDKNUXtkOjJ6f1ZlZTIMwk3 for file ../data/temp/model_60/training.jsonl\n",
      "Uploading training file\n",
      "Uploading validation file\n",
      "Submitting fine-tuning job\n",
      "Submitted job ftjob-14hf6eczeaaST4V6Tniso8DU for file ../data/temp/model_70/training.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Running this cell will start jobs with OpenAI and incur usage cost\n",
    "\n",
    "sizes_to_run = [50, 60, 70]\n",
    "sizes_to_run = [80, 90]\n",
    "\n",
    "submitted_jobs = []\n",
    "for sample_size in sizes_to_run:\n",
    "    training_data_path = f\"../data/temp/model_{sample_size}/training.jsonl\"\n",
    "    validation_data_path = f\"../data/temp/model_{sample_size}/validation.jsonl\"\n",
    "    job = runFineTuning(training_data_path, validation_data_path)\n",
    "    with open(f\"../data/temp/model_{sample_size}/job_start.json\", 'w') as f:\n",
    "        json.dump(job.__str__(), f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated at 2023-11-09 13:21:40.532381\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Training File</th>\n",
       "      <th>Status</th>\n",
       "      <th>Duration</th>\n",
       "      <th>TrainedTokens</th>\n",
       "      <th>TokensPerMinute</th>\n",
       "      <th>FT ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ftjob-14hf6eczeaaST4V6Tniso8DU</td>\n",
       "      <td>file-XC0lxrDfmQg4t4gAQ1jmNVge</td>\n",
       "      <td>running</td>\n",
       "      <td>9.192172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ftjob-kJDKNUXtkOjJ6f1ZlZTIMwk3</td>\n",
       "      <td>file-jBE3mjrdneN2u94yu9c8hhCh</td>\n",
       "      <td>running</td>\n",
       "      <td>9.242172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ftjob-LiL1r8rE2HEpdaj4KYnIjz9U</td>\n",
       "      <td>file-JyvEGeQTceZWqs5gtcwX314T</td>\n",
       "      <td>running</td>\n",
       "      <td>33.158839</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ftjob-Y9CLf0O6axyYeHU3b3pNFrZc</td>\n",
       "      <td>file-Dgml7KFJvBrAlIDQ5LlSSbVk</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>22.050000</td>\n",
       "      <td>16455</td>\n",
       "      <td>746.258503</td>\n",
       "      <td>ft:gpt-3.5-turbo-0613:hypercolor::8J4dFhGo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ftjob-FMNe8R1qb21f4m4LywYxcdxp</td>\n",
       "      <td>file-a4ci3mqKw1CbSyNrQUxpZza7</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>17.433333</td>\n",
       "      <td>8658</td>\n",
       "      <td>496.634799</td>\n",
       "      <td>ft:gpt-3.5-turbo-0613:hypercolor::8J4N4EYY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ftjob-Jlr2b3eW1qbSIJOjgrUbBk2y</td>\n",
       "      <td>file-B1y2Kgy61uxBA6KNOqHpvset</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>103.066667</td>\n",
       "      <td>32352</td>\n",
       "      <td>313.893920</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:aa-engineering::8IAIy8LD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ftjob-BM8V9hMp1nHn0v2Sn9YRagSg</td>\n",
       "      <td>file-LpT2K57tcfuXsO0fmtXLFibN</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>16455</td>\n",
       "      <td>209.617834</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:aa-engineering::8I9vALSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ftjob-v2MTWHznXSCoi9zIhV4xeGfv</td>\n",
       "      <td>file-fxIq8wsI48lNp8khtYfj4Flo</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>63.033333</td>\n",
       "      <td>8658</td>\n",
       "      <td>137.355896</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:aa-engineering::8I9g9RO0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ftjob-KUl5tSNid5Rq08EK9JFiySDt</td>\n",
       "      <td>file-tmOKf3KsbaOQLcIDMvx7lMbq</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>16.916667</td>\n",
       "      <td>31632</td>\n",
       "      <td>1869.871921</td>\n",
       "      <td>ft:gpt-3.5-turbo-0613:aa-engineering::8HnGqN6a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ftjob-hjCv26zXKV13we6T1GoZSU3I</td>\n",
       "      <td>file-MTHHGTfNOed6X1YWWF1zX8Ud</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>18.550000</td>\n",
       "      <td>23943</td>\n",
       "      <td>1290.727763</td>\n",
       "      <td>ft:gpt-3.5-turbo-0613:aa-engineering::8HnINqwQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ID                  Training File     Status  \\\n",
       "0  ftjob-14hf6eczeaaST4V6Tniso8DU  file-XC0lxrDfmQg4t4gAQ1jmNVge    running   \n",
       "1  ftjob-kJDKNUXtkOjJ6f1ZlZTIMwk3  file-jBE3mjrdneN2u94yu9c8hhCh    running   \n",
       "2  ftjob-LiL1r8rE2HEpdaj4KYnIjz9U  file-JyvEGeQTceZWqs5gtcwX314T    running   \n",
       "3  ftjob-Y9CLf0O6axyYeHU3b3pNFrZc  file-Dgml7KFJvBrAlIDQ5LlSSbVk  succeeded   \n",
       "4  ftjob-FMNe8R1qb21f4m4LywYxcdxp  file-a4ci3mqKw1CbSyNrQUxpZza7  succeeded   \n",
       "5  ftjob-Jlr2b3eW1qbSIJOjgrUbBk2y  file-B1y2Kgy61uxBA6KNOqHpvset  succeeded   \n",
       "6  ftjob-BM8V9hMp1nHn0v2Sn9YRagSg  file-LpT2K57tcfuXsO0fmtXLFibN  succeeded   \n",
       "7  ftjob-v2MTWHznXSCoi9zIhV4xeGfv  file-fxIq8wsI48lNp8khtYfj4Flo  succeeded   \n",
       "8  ftjob-KUl5tSNid5Rq08EK9JFiySDt  file-tmOKf3KsbaOQLcIDMvx7lMbq  succeeded   \n",
       "9  ftjob-hjCv26zXKV13we6T1GoZSU3I  file-MTHHGTfNOed6X1YWWF1zX8Ud  succeeded   \n",
       "\n",
       "     Duration  TrainedTokens  TokensPerMinute  \\\n",
       "0    9.192172              0         0.000000   \n",
       "1    9.242172              0         0.000000   \n",
       "2   33.158839              0         0.000000   \n",
       "3   22.050000          16455       746.258503   \n",
       "4   17.433333           8658       496.634799   \n",
       "5  103.066667          32352       313.893920   \n",
       "6   78.500000          16455       209.617834   \n",
       "7   63.033333           8658       137.355896   \n",
       "8   16.916667          31632      1869.871921   \n",
       "9   18.550000          23943      1290.727763   \n",
       "\n",
       "                                            FT ID  \n",
       "0                                            None  \n",
       "1                                            None  \n",
       "2                                            None  \n",
       "3      ft:gpt-3.5-turbo-0613:hypercolor::8J4dFhGo  \n",
       "4      ft:gpt-3.5-turbo-0613:hypercolor::8J4N4EYY  \n",
       "5  ft:gpt-3.5-turbo-1106:aa-engineering::8IAIy8LD  \n",
       "6  ft:gpt-3.5-turbo-1106:aa-engineering::8I9vALSP  \n",
       "7  ft:gpt-3.5-turbo-1106:aa-engineering::8I9g9RO0  \n",
       "8  ft:gpt-3.5-turbo-0613:aa-engineering::8HnGqN6a  \n",
       "9  ft:gpt-3.5-turbo-0613:aa-engineering::8HnINqwQ  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while True:\n",
    "    current_jobs = client.fine_tuning.jobs.list(limit=10)\n",
    "    df = makeJobsDataframe(current_jobs.data)\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Updated at {datetime.now()}\")\n",
    "    display(df)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other useful commands\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "#client.fine_tuning.jobs.list_events(id=job.id, limit=10)\n",
    "#client.fine_tuning.jobs.cancel(job.id)\n",
    "#client.fine_tuning.jobs.retrieve(id='ftjob-KUl5tSNid5Rq08EK9JFiySDt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Size to Model ID\n",
    "completed_models = {\n",
    "    50: 'ft:gpt-3.5-turbo-0613:hypercolor::8J4N4EYY',\n",
    "    100: 'ft:gpt-3.5-turbo-0613:hypercolor::8J4dFhGo',\n",
    "    200: 'ft:gpt-3.5-turbo-0613:aa-engineering::8IAIy8LD'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpamClassification_FineTune(fineTunedModelId, prompt):\n",
    "  completion = client.chat.completions.create(\n",
    "    model=fineTunedModelId,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": systemPrompt},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  result = completion.choices[0].message.content.lower() == 'spam'\n",
    "  # print(prompt, \"=>\", result)\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSpamClassification_FineTune(completed_models[50], \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSpamClassification_FineTune(completed_models[50], \"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
