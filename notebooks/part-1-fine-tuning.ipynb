{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This notebook demonstrates fine-tuning GPT 3.5 for text classification on a dataset of SMS text messages.\n",
    "\n",
    "The following steps are covered:\n",
    "\n",
    "* Loading and enriching SMS dataset\n",
    "* Downsampling the dataset for fine tuning\n",
    "* Training three fine-tuned models with sizes: 50, 100, 200\n",
    "* Experimenting with the fine-tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "* Python 3 environment\n",
    "    * python3 -m venv venv\n",
    "    * Select venv kernel in VS Code\n",
    "        * Upper-right corner of notebook in editor\n",
    "* OpenAI Account\n",
    "    * Need a valid API key: https://platform.openai.com/account/api-keys\n",
    "* OpenAI Python Module\n",
    "    * https://github.com/openai/openai-python\n",
    "    * pip install --pre openai\n",
    "    * Configure with API Key: \n",
    "        * Create .env file with `OPENAI_API_KEY=sk_XXXX_...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# %pip install pandas\n",
    "# %pip install python-dotenv\n",
    "# %pip install openai\n",
    "# %pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* https://platform.openai.com/docs/guides/fine-tuning\n",
    "* https://platform.openai.com/docs/api-reference/fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "# from openai import AsyncOpenAI\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.util import getTrainTestSplit, makeJobsDataframe, distributionPreservingDownsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv; load_dotenv()\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SMS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sms data file with 5572 rows, kept 5169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prompt</th>\n",
       "      <th>spam_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             prompt  spam_flag\n",
       "0   ham  Go until jurong point, crazy.. Available only ...      False\n",
       "1   ham                      Ok lar... Joking wif u oni...      False\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...       True\n",
       "3   ham  U dun say so early hor... U c already then say...      False\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam_all = pd.read_csv('../data/kaggle_sms_spam.csv', encoding='latin-1')[['label', 'prompt']]\n",
    "sms_spam_all['spam_flag'] = sms_spam_all['label'].apply(lambda x: True if x == 'spam' else False)\n",
    "sms_spam = sms_spam_all.drop_duplicates(subset=['prompt'])\n",
    "print(\"Loaded sms data file with {} rows, kept {}\".format(len(sms_spam_all), len(sms_spam)))\n",
    "sms_spam.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemPrompt = \"You are a system for categorizing SMS text messages as being unwanted spam or normal messages.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create downsampled datasets at various sizes\n",
    "\n",
    "We want to see how the dataset size affects model training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90, 100, 200]\n",
    "test_data_size = 200\n",
    "\n",
    "all_train_data, test_data = getTrainTestSplit(sms_spam, 'spam_flag', max(sample_sizes), test_data_size)\n",
    "\n",
    "validation_data_path = \"../data/temp\"\n",
    "os.makedirs(validation_data_path, exist_ok=True)\n",
    "with open(f\"{validation_data_path}/validation.jsonl\", 'w') as f:\n",
    "    for index, row in test_data.iterrows():\n",
    "        f.write(json.dumps({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": systemPrompt},\n",
    "                {\"role\": \"user\", \"content\": row['prompt']},\n",
    "                {\"role\": \"assistant\", \"content\": \"spam\" if row['spam_flag'] else \"ham\"}\n",
    "            ]\n",
    "        }) + \"\\n\")\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    \n",
    "    model_path = f\"../data/temp/model_{sample_size}\"\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    train_data = distributionPreservingDownsample(all_train_data, 'spam_flag', sample_size)\n",
    "\n",
    "    with open(f\"{model_path}/training.jsonl\", 'w') as f:\n",
    "        for index, row in train_data.iterrows():\n",
    "            f.write(json.dumps({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": systemPrompt},\n",
    "                    {\"role\": \"user\", \"content\": row['prompt']},\n",
    "                    {\"role\": \"assistant\", \"content\": \"spam\" if row['spam_flag'] else \"ham\"}\n",
    "                ]\n",
    "            }) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundationModel = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "def runFineTuning(training_data_path, validation_data_path):\n",
    "    print(\"Uploading training file: {}\".format(training_data_path))\n",
    "    training_file = client.files.create(\n",
    "        file=open(training_data_path, \"rb\"),\n",
    "        purpose='fine-tune'\n",
    "    )\n",
    "    print(\"Uploading validation file: {}\".format(validation_data_path))\n",
    "    validation_file = client.files.create(\n",
    "        file=open(validation_data_path, \"rb\"),\n",
    "        purpose='fine-tune'\n",
    "    )\n",
    "    print(\"Submitting fine-tuning job for foundation model {}\".format(foundationModel))\n",
    "    job = client.fine_tuning.jobs.create(training_file=training_file.id, validation_file=validation_file.id, model=foundationModel)\n",
    "    print(\"Submitted job {}\".format(job.id))\n",
    "    return job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a training job for each sample size we are testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading training file: ../data/temp/model_35/training.jsonl\n",
      "Uploading validation file: ../data/temp/validation.jsonl\n",
      "Submitting fine-tuning job for foundation model gpt-3.5-turbo-1106\n",
      "Submitted job ftjob-Dp5kaFNVOJikGve79K5M9KVH\n"
     ]
    }
   ],
   "source": [
    "# Running this cell will start jobs with OpenAI and incur usage cost\n",
    "\n",
    "# sizes_to_run = [10, 15, 20]\n",
    "# sizes_to_run = [25, 30, 35]\n",
    "sizes_to_run = [40, 45, 50]\n",
    "# sizes_to_run = [60, 70, 80]\n",
    "# sizes_to_run = [90, 100, 200]\n",
    "\n",
    "\n",
    "submitted_jobs = []\n",
    "for sample_size in sizes_to_run:\n",
    "    training_data_path = f\"../data/temp/model_{sample_size}/training.jsonl\"\n",
    "    validation_data_path = f\"../data/temp/validation.jsonl\"\n",
    "    job = runFineTuning(training_data_path, validation_data_path)\n",
    "    with open(f\"../data/temp/model_{sample_size}/job_start.json\", 'w') as f:\n",
    "        json.dump(job.__str__(), f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated at 2023-11-09 21:17:32.785522\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Training File</th>\n",
       "      <th>Status</th>\n",
       "      <th>Duration</th>\n",
       "      <th>TrainedTokens</th>\n",
       "      <th>TokensPerMinute</th>\n",
       "      <th>FT ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ftjob-yvzU8bBhvblvjvnh7qBmvcXb</td>\n",
       "      <td>file-RH8yR4RaQ8a1iTp6dbsb4lpE</td>\n",
       "      <td>running</td>\n",
       "      <td>5.751037</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ftjob-Rc8n7qsLcoRIqwlfX4eVjnnk</td>\n",
       "      <td>file-N09I06xISGTANtsWcTkFbvSo</td>\n",
       "      <td>running</td>\n",
       "      <td>9.851037</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ftjob-CqneHDnaVERvElsAVcdYaTGL</td>\n",
       "      <td>file-RfgJ0qWNehDhKMVe81OtZMkA</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>23.033333</td>\n",
       "      <td>13308</td>\n",
       "      <td>577.771346</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JCJ48nL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ftjob-f6FiM7pHeGKccwBwziWd1c7w</td>\n",
       "      <td>file-yzfNU9aY8KHNgcUiUWz9qQdQ</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>20.216667</td>\n",
       "      <td>11676</td>\n",
       "      <td>577.543281</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JCDiUJu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ftjob-TyDA4tqEd6WPYB2DrvsRqk1a</td>\n",
       "      <td>file-CTC5xzpESQ0vNuUr73BHaFeA</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>9954</td>\n",
       "      <td>517.090909</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JC9mQ5T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ftjob-rzc89kHag5HSWCQ1j5LFxlkG</td>\n",
       "      <td>file-OrEFBDBCeM84QxKmKdCKOZO4</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>8532</td>\n",
       "      <td>520.243902</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JBwWNER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ftjob-rDXDYFQzCUQZMI9v5NOETuju</td>\n",
       "      <td>file-kqozmupBqqo4vkLlDrqYvRMV</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>7800</td>\n",
       "      <td>547.368421</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JBtje7h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ftjob-dEj5ggwOc2Qf4yfGNiTcDkIL</td>\n",
       "      <td>file-WR06movHzKQ8bBuWSFzTHqD9</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>23.416667</td>\n",
       "      <td>6927</td>\n",
       "      <td>295.814947</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JBqnboO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ftjob-lRMXQrXBZYnfFaGjbEaBCSl9</td>\n",
       "      <td>file-uoYnFeUz5smrJJAMDnuWf2Ny</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>6066</td>\n",
       "      <td>491.837838</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JBfhbX6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ftjob-IK1WleV7VSxmGwQz2RDyL6Ps</td>\n",
       "      <td>file-vNV41RPJU5lzteI2bMZR2QUY</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>22.116667</td>\n",
       "      <td>5247</td>\n",
       "      <td>237.241899</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JBgIVeX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ID                  Training File     Status  \\\n",
       "0  ftjob-yvzU8bBhvblvjvnh7qBmvcXb  file-RH8yR4RaQ8a1iTp6dbsb4lpE    running   \n",
       "1  ftjob-Rc8n7qsLcoRIqwlfX4eVjnnk  file-N09I06xISGTANtsWcTkFbvSo    running   \n",
       "2  ftjob-CqneHDnaVERvElsAVcdYaTGL  file-RfgJ0qWNehDhKMVe81OtZMkA  succeeded   \n",
       "3  ftjob-f6FiM7pHeGKccwBwziWd1c7w  file-yzfNU9aY8KHNgcUiUWz9qQdQ  succeeded   \n",
       "4  ftjob-TyDA4tqEd6WPYB2DrvsRqk1a  file-CTC5xzpESQ0vNuUr73BHaFeA  succeeded   \n",
       "5  ftjob-rzc89kHag5HSWCQ1j5LFxlkG  file-OrEFBDBCeM84QxKmKdCKOZO4  succeeded   \n",
       "6  ftjob-rDXDYFQzCUQZMI9v5NOETuju  file-kqozmupBqqo4vkLlDrqYvRMV  succeeded   \n",
       "7  ftjob-dEj5ggwOc2Qf4yfGNiTcDkIL  file-WR06movHzKQ8bBuWSFzTHqD9  succeeded   \n",
       "8  ftjob-lRMXQrXBZYnfFaGjbEaBCSl9  file-uoYnFeUz5smrJJAMDnuWf2Ny  succeeded   \n",
       "9  ftjob-IK1WleV7VSxmGwQz2RDyL6Ps  file-vNV41RPJU5lzteI2bMZR2QUY  succeeded   \n",
       "\n",
       "    Duration  TrainedTokens  TokensPerMinute  \\\n",
       "0   5.751037              0         0.000000   \n",
       "1   9.851037              0         0.000000   \n",
       "2  23.033333          13308       577.771346   \n",
       "3  20.216667          11676       577.543281   \n",
       "4  19.250000           9954       517.090909   \n",
       "5  16.400000           8532       520.243902   \n",
       "6  14.250000           7800       547.368421   \n",
       "7  23.416667           6927       295.814947   \n",
       "8  12.333333           6066       491.837838   \n",
       "9  22.116667           5247       237.241899   \n",
       "\n",
       "                                        FT ID  \n",
       "0                                        None  \n",
       "1                                        None  \n",
       "2  ft:gpt-3.5-turbo-1106:hypercolor::8JCJ48nL  \n",
       "3  ft:gpt-3.5-turbo-1106:hypercolor::8JCDiUJu  \n",
       "4  ft:gpt-3.5-turbo-1106:hypercolor::8JC9mQ5T  \n",
       "5  ft:gpt-3.5-turbo-1106:hypercolor::8JBwWNER  \n",
       "6  ft:gpt-3.5-turbo-1106:hypercolor::8JBtje7h  \n",
       "7  ft:gpt-3.5-turbo-1106:hypercolor::8JBqnboO  \n",
       "8  ft:gpt-3.5-turbo-1106:hypercolor::8JBfhbX6  \n",
       "9  ft:gpt-3.5-turbo-1106:hypercolor::8JBgIVeX  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active jobs: 2\n",
      "Ready to submit new job, currently active: 2\n",
      "Uploading training file: ../data/temp/model_200/training.jsonl\n",
      "Uploading validation file: ../data/temp/validation.jsonl\n",
      "Submitting fine-tuning job for foundation model gpt-3.5-turbo-1106\n",
      "Submitted job ftjob-79ZCSpZIG2Si87yDBJyOWpEk\n",
      "json path: ../data/temp/model_200/job_start.json\n"
     ]
    }
   ],
   "source": [
    "sizes_to_run = [10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80 ,90, 100, 200]\n",
    "# sizes_to_run = [50, 60, 70]\n",
    "all_job_data = []\n",
    "for sample_size in sample_sizes:\n",
    "    all_job_data.append({\n",
    "        'sample_size': sample_size,\n",
    "        'job': None\n",
    "    })\n",
    "\n",
    "scheduled_jobs = []\n",
    "while len(scheduled_jobs) < len(all_job_data):\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    current_jobs = client.fine_tuning.jobs.list(limit=10)\n",
    "    df = makeJobsDataframe(current_jobs.data)\n",
    "    display(df)\n",
    "\n",
    "    num_active_jobs = len([j for j in current_jobs.data if j.status not in [\"succeeded\", \"cancelled\", \"error\"]])\n",
    "    print(\"Active jobs: {}\".format(num_active_jobs))\n",
    "    if num_active_jobs < 3:\n",
    "\n",
    "        print(\"Ready to submit new job, currently active: {}\".format(num_active_jobs))\n",
    "        for job_data in all_job_data:\n",
    "            if job_data['job'] is None:\n",
    "                model_path = f\"../data/temp/model_{job_data['sample_size']}\"\n",
    "                training_data_path = f\"{model_path}/training.jsonl\"\n",
    "                validation_data_path = f\"../data/temp/validation.jsonl\"\n",
    "                job = runFineTuning(training_data_path, validation_data_path)\n",
    "\n",
    "                print(\"json path: {}\".format(f\"{model_path}/job_start.json\"))\n",
    "\n",
    "                with open(f\"{model_path}/job_start.json\", 'w') as f:\n",
    "                    json.dump(job.__str__(), f, indent=4)\n",
    "                job_data['job'] = job.id\n",
    "                scheduled_jobs.append(job)\n",
    "                break\n",
    "    else:\n",
    "        print(\"Waiting for jobs to finish, {} remain\".format(len(all_job_data) - len(scheduled_jobs)))\n",
    "        print(f\"Updated at {datetime.now()}\")\n",
    "        time.sleep(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated at 2023-11-09 22:19:36.245923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Training File</th>\n",
       "      <th>Status</th>\n",
       "      <th>Duration</th>\n",
       "      <th>TrainedTokens</th>\n",
       "      <th>TokensPerMinute</th>\n",
       "      <th>FT ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ftjob-79ZCSpZIG2Si87yDBJyOWpEk</td>\n",
       "      <td>file-LefbTqmZpYmr1DK8qSpRdLqD</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>58.450000</td>\n",
       "      <td>32352</td>\n",
       "      <td>553.498717</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JDE3R1k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ftjob-yvzU8bBhvblvjvnh7qBmvcXb</td>\n",
       "      <td>file-RH8yR4RaQ8a1iTp6dbsb4lpE</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>28.016667</td>\n",
       "      <td>16446</td>\n",
       "      <td>587.007733</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JCf0Fge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ftjob-Rc8n7qsLcoRIqwlfX4eVjnnk</td>\n",
       "      <td>file-N09I06xISGTANtsWcTkFbvSo</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>25.583333</td>\n",
       "      <td>15060</td>\n",
       "      <td>588.664495</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JCYhUyu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ftjob-CqneHDnaVERvElsAVcdYaTGL</td>\n",
       "      <td>file-RfgJ0qWNehDhKMVe81OtZMkA</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>23.033333</td>\n",
       "      <td>13308</td>\n",
       "      <td>577.771346</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JCJ48nL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ftjob-f6FiM7pHeGKccwBwziWd1c7w</td>\n",
       "      <td>file-yzfNU9aY8KHNgcUiUWz9qQdQ</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>20.216667</td>\n",
       "      <td>11676</td>\n",
       "      <td>577.543281</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JCDiUJu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ftjob-TyDA4tqEd6WPYB2DrvsRqk1a</td>\n",
       "      <td>file-CTC5xzpESQ0vNuUr73BHaFeA</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>9954</td>\n",
       "      <td>517.090909</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JC9mQ5T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ftjob-rzc89kHag5HSWCQ1j5LFxlkG</td>\n",
       "      <td>file-OrEFBDBCeM84QxKmKdCKOZO4</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>8532</td>\n",
       "      <td>520.243902</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JBwWNER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ftjob-rDXDYFQzCUQZMI9v5NOETuju</td>\n",
       "      <td>file-kqozmupBqqo4vkLlDrqYvRMV</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>7800</td>\n",
       "      <td>547.368421</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JBtje7h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ftjob-dEj5ggwOc2Qf4yfGNiTcDkIL</td>\n",
       "      <td>file-WR06movHzKQ8bBuWSFzTHqD9</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>23.416667</td>\n",
       "      <td>6927</td>\n",
       "      <td>295.814947</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JBqnboO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ftjob-lRMXQrXBZYnfFaGjbEaBCSl9</td>\n",
       "      <td>file-uoYnFeUz5smrJJAMDnuWf2Ny</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>6066</td>\n",
       "      <td>491.837838</td>\n",
       "      <td>ft:gpt-3.5-turbo-1106:hypercolor::8JBfhbX6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ID                  Training File     Status  \\\n",
       "0  ftjob-79ZCSpZIG2Si87yDBJyOWpEk  file-LefbTqmZpYmr1DK8qSpRdLqD  succeeded   \n",
       "1  ftjob-yvzU8bBhvblvjvnh7qBmvcXb  file-RH8yR4RaQ8a1iTp6dbsb4lpE  succeeded   \n",
       "2  ftjob-Rc8n7qsLcoRIqwlfX4eVjnnk  file-N09I06xISGTANtsWcTkFbvSo  succeeded   \n",
       "3  ftjob-CqneHDnaVERvElsAVcdYaTGL  file-RfgJ0qWNehDhKMVe81OtZMkA  succeeded   \n",
       "4  ftjob-f6FiM7pHeGKccwBwziWd1c7w  file-yzfNU9aY8KHNgcUiUWz9qQdQ  succeeded   \n",
       "5  ftjob-TyDA4tqEd6WPYB2DrvsRqk1a  file-CTC5xzpESQ0vNuUr73BHaFeA  succeeded   \n",
       "6  ftjob-rzc89kHag5HSWCQ1j5LFxlkG  file-OrEFBDBCeM84QxKmKdCKOZO4  succeeded   \n",
       "7  ftjob-rDXDYFQzCUQZMI9v5NOETuju  file-kqozmupBqqo4vkLlDrqYvRMV  succeeded   \n",
       "8  ftjob-dEj5ggwOc2Qf4yfGNiTcDkIL  file-WR06movHzKQ8bBuWSFzTHqD9  succeeded   \n",
       "9  ftjob-lRMXQrXBZYnfFaGjbEaBCSl9  file-uoYnFeUz5smrJJAMDnuWf2Ny  succeeded   \n",
       "\n",
       "    Duration  TrainedTokens  TokensPerMinute  \\\n",
       "0  58.450000          32352       553.498717   \n",
       "1  28.016667          16446       587.007733   \n",
       "2  25.583333          15060       588.664495   \n",
       "3  23.033333          13308       577.771346   \n",
       "4  20.216667          11676       577.543281   \n",
       "5  19.250000           9954       517.090909   \n",
       "6  16.400000           8532       520.243902   \n",
       "7  14.250000           7800       547.368421   \n",
       "8  23.416667           6927       295.814947   \n",
       "9  12.333333           6066       491.837838   \n",
       "\n",
       "                                        FT ID  \n",
       "0  ft:gpt-3.5-turbo-1106:hypercolor::8JDE3R1k  \n",
       "1  ft:gpt-3.5-turbo-1106:hypercolor::8JCf0Fge  \n",
       "2  ft:gpt-3.5-turbo-1106:hypercolor::8JCYhUyu  \n",
       "3  ft:gpt-3.5-turbo-1106:hypercolor::8JCJ48nL  \n",
       "4  ft:gpt-3.5-turbo-1106:hypercolor::8JCDiUJu  \n",
       "5  ft:gpt-3.5-turbo-1106:hypercolor::8JC9mQ5T  \n",
       "6  ft:gpt-3.5-turbo-1106:hypercolor::8JBwWNER  \n",
       "7  ft:gpt-3.5-turbo-1106:hypercolor::8JBtje7h  \n",
       "8  ft:gpt-3.5-turbo-1106:hypercolor::8JBqnboO  \n",
       "9  ft:gpt-3.5-turbo-1106:hypercolor::8JBfhbX6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/andrew/Software/hypercolor/applied-ai-fine-tuning/notebooks/part-1-fine-tuning.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrew/Software/hypercolor/applied-ai-fine-tuning/notebooks/part-1-fine-tuning.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUpdated at \u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrew/Software/hypercolor/applied-ai-fine-tuning/notebooks/part-1-fine-tuning.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m display(df)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andrew/Software/hypercolor/applied-ai-fine-tuning/notebooks/part-1-fine-tuning.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m10\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Running this cell will continuously monitor the status of the jobs and display the results\n",
    "# While this monitoring is running you will not be able to run other cells in this notebook\n",
    "# Cancel the cell to stop monitoring\n",
    "\n",
    "while True:\n",
    "    current_jobs = client.fine_tuning.jobs.list(limit=10)\n",
    "    df = makeJobsDataframe(current_jobs.data)\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Updated at {datetime.now()}\")\n",
    "    display(df)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-CqneHDnaVERvElsAVcdYaTGL', created_at=1699584848, error=None, fine_tuned_model='ft:gpt-3.5-turbo-1106:hypercolor::8JCJ48nL', finished_at=1699586230, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-n3iT5I0sZST0QX1nSKkPHmb7', result_files=['file-0UqqpkrOLdDGWfl35yI2BatS'], status='succeeded', trained_tokens=13308, training_file='file-RfgJ0qWNehDhKMVe81OtZMkA', validation_file='file-YUY9bd7zDbcXXcpa8FurH6DF')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other useful commands\n",
    "# client.fine_tuning.jobs.list(limit=10)\n",
    "#client.fine_tuning.jobs.list_events(id=job.id, limit=10)\n",
    "# client.fine_tuning.jobs.cancel('ftjob-eFMitAHD9fqWwYrrADQrNjKL')\n",
    "client.fine_tuning.jobs.retrieve('ftjob-CqneHDnaVERvElsAVcdYaTGL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 'ft:gpt-3.5-turbo-1106:hypercolor::8JBJIU02',\n",
       " 15: 'ft:gpt-3.5-turbo-1106:hypercolor::8JBKfVCh',\n",
       " 20: 'ft:gpt-3.5-turbo-1106:hypercolor::8JBTXhIj',\n",
       " 25: 'ft:gpt-3.5-turbo-1106:hypercolor::8JBTuMaq',\n",
       " 30: 'ft:gpt-3.5-turbo-1106:hypercolor::8JBgIVeX',\n",
       " 35: 'ft:gpt-3.5-turbo-1106:hypercolor::8JBfhbX6',\n",
       " 40: 'ft:gpt-3.5-turbo-1106:hypercolor::8JBqnboO',\n",
       " 45: 'ft:gpt-3.5-turbo-1106:hypercolor::8JBtje7h',\n",
       " 50: 'ft:gpt-3.5-turbo-1106:hypercolor::8JBwWNER',\n",
       " 60: 'ft:gpt-3.5-turbo-1106:hypercolor::8JC9mQ5T',\n",
       " 70: 'ft:gpt-3.5-turbo-1106:hypercolor::8JCDiUJu',\n",
       " 80: 'ft:gpt-3.5-turbo-1106:hypercolor::8JCJ48nL',\n",
       " 90: 'ft:gpt-3.5-turbo-1106:hypercolor::8JCYhUyu',\n",
       " 100: 'ft:gpt-3.5-turbo-1106:hypercolor::8JCf0Fge',\n",
       " 200: 'ft:gpt-3.5-turbo-1106:hypercolor::8JDE3R1k'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def buildFineTuneModelIdMap(job_data_list):\n",
    "    fine_tune_model_id_map = {}\n",
    "    for job_data in job_data_list:\n",
    "        job = client.fine_tuning.jobs.retrieve(job_data['job'])\n",
    "        # if job.status == 'succeeded':\n",
    "        fine_tune_model_id_map[job_data['sample_size']] = job.fine_tuned_model\n",
    "\n",
    "    return fine_tune_model_id_map\n",
    "\n",
    "fine_tuned_models = buildFineTuneModelIdMap(all_job_data)\n",
    "fine_tuned_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpamClassification_FineTune(fineTunedModelId, prompt):\n",
    "  completion = client.chat.completions.create(\n",
    "    model=fineTunedModelId,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": systemPrompt},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  result = completion.choices[0].message.content.lower() == 'spam'\n",
    "  # print(prompt, \"=>\", result)\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSpamClassification_FineTune(fine_tuned_models[50], \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSpamClassification_FineTune(fine_tuned_models[50], \"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
